{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import os #for data load\n",
    "from scienceie_loader import load_tokenized_data, load_data_with_char_offsets #for data preparing also customize dataset requirments for load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loading from data folder\n",
    "data_root = 'data'\n",
    "data_train = os.path.join(data_root, 'train2')\n",
    "data_test = os.path.join(data_root, 'semeval_articles_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting into train and test dataset and with customize function that comes with dataset\n",
    "# and this function define in scienceie_loader.py\n",
    "train_docs, train_rels, _ = load_tokenized_data(data_train)\n",
    "test_docs, test_rels, _ = load_tokenized_data(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepareing Data for HMM\n",
    "1. Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtag = defaultdict(int) # emission freqs\n",
    "unitag = defaultdict(int) # unigram freqs of tags\n",
    "bitag = defaultdict(int) # bigram freqs of tags\n",
    "tritag = defaultdict(int) # trigram freqs of tags\n",
    "\n",
    "tag_penult = ''\n",
    "tag_last = ''\n",
    "tag_current = ''\n",
    "\n",
    "for l in train_docs:\n",
    "    for word,tag in l:\n",
    "        if not l:\n",
    "            tag_penult = tag_last\n",
    "            tag_last = tag_current\n",
    "            tag_current = ''\n",
    "            # update sentence boundary case\n",
    "            if tag_last != '' and tag_penult != '':\n",
    "                # update bitag freqs\n",
    "                bitag[(tag_last, tag_current)] += 1\n",
    "                # update tritag freqs\n",
    "                tritag[(tag_penult, tag_last, tag_current)] += 1\n",
    "        else:\n",
    "            tag_penult = tag_last\n",
    "            tag_last = tag_current\n",
    "            tag_current = tag\n",
    "            # update emission freqs\n",
    "            wordtag[(word,tag)] += 1\n",
    "            # update unitag freqs\n",
    "            unitag[tag] += 1\n",
    "            # update bitag freqs\n",
    "            bitag[(tag_last, tag_current)] += 1\n",
    "            # update tritag freqs\n",
    "            tritag[(tag_penult, tag_last, tag_current)] += 1\n",
    "            # update starting bigrams\n",
    "            if tag_last == '' and tag_penult == '':\n",
    "                bitag[('','')] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2850875188519722e-05\n",
      "0.871086312671885\n"
     ]
    }
   ],
   "source": [
    "word,tag=train_docs[0][0][0], train_docs[0][0][1]\n",
    "print(float(wordtag[(word,tag)])/unitag[tag])\n",
    "print(float(tritag[(tag_penult, tag_last, tag_current)])/bitag[(tag_penult, tag_last)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define method and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unknown word handeling method start\n",
    "if 'UNK':\n",
    "    new = defaultdict(int)\n",
    "    # change words with freq <5 into unknown words \"<UNK>\"\n",
    "    for (word,tag) in wordtag:\n",
    "        new[(word,tag)] = wordtag[(word,tag)]\n",
    "        if wordtag[(word,tag)] < 5:\n",
    "            new[('<UNK>',tag)] += wordtag[(word,tag)]\n",
    "    wordtag = new\n",
    "#end\n",
    "\n",
    "#train data\n",
    "words = set([key[0] for key in wordtag.keys()])\n",
    "tags = set(unitag.keys())\n",
    "E = defaultdict(int)\n",
    "Q = defaultdict(int)\n",
    "for (word,tag) in wordtag:\n",
    "    E[(word,tag)] = float(wordtag[(word,tag)])/unitag[tag]\n",
    "for (tag_penult, tag_last, tag_current) in tritag:\n",
    "    Q[(tag_penult, tag_last, tag_current)] = float(tritag[(tag_penult, tag_last, tag_current)])/bitag[(tag_penult, tag_last)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Viterbi Algorithm for tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def viterbi(sent,method='UNK'):\n",
    "        V = {}\n",
    "        path = {}\n",
    "        # init\n",
    "        V[0,'',''] = 1\n",
    "        path['',''] = []\n",
    "        # run\n",
    "        for k in range(1,len(sent)+1):\n",
    "            temp_path = {}\n",
    "            word = get_word(sent,k-1)\n",
    "            # handling unknown words in test set using low freq words in training set\n",
    "            if word not in words:\n",
    "                if method=='UNK':\n",
    "                    word = '<UNK>'\n",
    "            for u in get_possible_tags(k-1):\n",
    "                for v in get_possible_tags(k):\n",
    "                    V[k,u,v],prev_w = max([(V[k-1,w,u] * Q[w,u,v] * E[word,v],w) for w in get_possible_tags(k-2)])\n",
    "                    temp_path[u,v] = path[prev_w,u] + [v]\n",
    "            path = temp_path\n",
    "        # last step\n",
    "        prob,umax,vmax = max([(V[len(sent),u,v] * Q[u,v,''],u,v) for u in tags for v in tags])\n",
    "        return path[umax,vmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_possible_tags(k):\n",
    "        if k == -1:\n",
    "            return set([''])\n",
    "        if k == 0:\n",
    "            return set([''])\n",
    "        else:\n",
    "            return tags\n",
    "\n",
    "    def get_word(sent,k):\n",
    "        if k < 0:\n",
    "            return ''\n",
    "        else:\n",
    "            return sent[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending test docs in an array for predict\n",
    "sent=[]\n",
    "s_tags=[]\n",
    "for i in test_docs:\n",
    "    s=[]\n",
    "    st=[]\n",
    "    for word,tag in i:\n",
    "        s.append(word)\n",
    "        st.append(tag)\n",
    "    sent.append(s)\n",
    "    s_tags.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.82120680665497\n"
     ]
    }
   ],
   "source": [
    "#Evaluating\n",
    "CP=NP=0\n",
    "for i in range(len(sent)):\n",
    "    path=viterbi(sent[i], \"UNK\")\n",
    "    for j in range(len(sent[i])):\n",
    "        if s_tags[i][j]==path[j]:\n",
    "            CP+=1\n",
    "        NP+=1\n",
    "acc=CP/NP\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First O\n",
      "results O\n",
      "from O\n",
      "RHIC B-Task\n",
      "on I-Task\n",
      "charged I-Task\n",
      "multiplicities I-Task\n",
      ", I-Task\n",
      "evolution I-Task\n",
      "of I-Task\n",
      "multiplicities I-Task\n",
      "with I-Task\n",
      "centrality I-Task\n",
      ", O\n",
      "particle O\n",
      "ratios O\n",
      "and O\n",
      "transverse B-Process\n",
      "momentum I-Process\n",
      "distributions I-Process\n",
      "in O\n",
      "central O\n",
      "and O\n",
      "minimum O\n",
      "bias O\n",
      "collisions B-Process\n",
      ", O\n",
      "are O\n",
      "analyzed O\n",
      "in O\n",
      "a O\n",
      "string B-Process\n",
      "model I-Process\n",
      "which O\n",
      "includes O\n",
      "hard B-Process\n",
      "collisions I-Process\n",
      ", O\n",
      "collectivity O\n",
      "in O\n",
      "the O\n",
      "initial O\n",
      "state O\n",
      "considered O\n",
      "as O\n",
      "string B-Process\n",
      "fusion I-Process\n",
      ", O\n",
      "and O\n",
      "rescattering B-Task\n",
      "of I-Task\n",
      "the I-Task\n",
      "produced I-Task\n",
      "secondaries. I-Task\n",
      "Multiplicities I-Task\n",
      "and I-Task\n",
      "their I-Task\n",
      "evolution I-Task\n",
      "with I-Task\n",
      "centrality I-Task\n",
      "are O\n",
      "successfully O\n",
      "reproduced. B-Process\n",
      "Transverse I-Process\n",
      "momentum I-Process\n",
      "distributions I-Process\n",
      "in I-Process\n",
      "the I-Process\n",
      "model I-Process\n",
      "show O\n",
      "a O\n",
      "larger O\n",
      "pT-tail O\n",
      "than O\n",
      "experimental B-Material\n",
      "data I-Material\n",
      ", O\n",
      "disagreement O\n",
      "which O\n",
      "grows O\n",
      "with O\n",
      "increasing B-Task\n",
      "centrality. I-Task\n",
      "Discrepancies I-Task\n",
      "with I-Task\n",
      "particle I-Task\n",
      "ratios O\n",
      "appear O\n",
      "and O\n",
      "are O\n",
      "examined O\n",
      "comparing O\n",
      "with O\n",
      "previous O\n",
      "features O\n",
      "of O\n",
      "the O\n",
      "model O\n",
      "at O\n",
      "SPS O\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "i=random.randint(0,len(sent))\n",
    "path=viterbi(sent[0], method='UNK')\n",
    "for word,p_tags in zip(sent[0],path):\n",
    "    print(word, p_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
